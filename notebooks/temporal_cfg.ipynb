{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from tuneavideo.models.unet_with_controlnet import UNet2DConditionModel\n",
    "from tuneavideo.data.dataset import TuneAVideoMoreShotDataset\n",
    "from tuneavideo.models.unet import UNet3DConditionModel\n",
    "from tuneavideo.pipelines.pipeline_tuneavideo import TuneAVideoPipeline\n",
    "from tuneavideo.pipelines.pipeline_tuneavideo_controlnet import TuneAVideoControlNetPipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from tuneavideo.models.controlnet_blocks import InflatedControlNetInputHintBlock3D, ControlNetInputHintBlock\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPTokenizer\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet3DConditionModel(sample_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CrossAttention.forward() got an unexpected keyword argument 'use_normal_attn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder_hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m320\u001b[39m, \u001b[39m768\u001b[39m)\n\u001b[1;32m      4\u001b[0m hint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m res \u001b[39m=\u001b[39m unet(sample, timestep, encoder_hidden_states)\n",
      "File \u001b[0;32m/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/disks/disk_main/projects/Tune-A-Video/notebooks/../tuneavideo/models/unet.py:405\u001b[0m, in \u001b[0;36mUNet3DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, attention_mask, controlnet_hint, control, return_dict, use_normal_attn)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mfor\u001b[39;00m downsample_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_blocks:\n\u001b[1;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    402\u001b[0m         \u001b[39mhasattr\u001b[39m(downsample_block, \u001b[39m\"\u001b[39m\u001b[39mhas_cross_attention\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    403\u001b[0m         \u001b[39mand\u001b[39;00m downsample_block\u001b[39m.\u001b[39mhas_cross_attention\n\u001b[1;32m    404\u001b[0m     ):\n\u001b[0;32m--> 405\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m downsample_block(\n\u001b[1;32m    406\u001b[0m             hidden_states\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    407\u001b[0m             temb\u001b[39m=\u001b[39;49memb,\n\u001b[1;32m    408\u001b[0m             encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    409\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    410\u001b[0m             use_normal_attn\u001b[39m=\u001b[39;49muse_normal_attn,\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m downsample_block(hidden_states\u001b[39m=\u001b[39msample, temb\u001b[39m=\u001b[39memb)\n",
      "File \u001b[0;32m/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/disks/disk_main/projects/Tune-A-Video/notebooks/../tuneavideo/models/unet_blocks.py:308\u001b[0m, in \u001b[0;36mCrossAttnDownBlock3D.forward\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, use_normal_attn)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m         hidden_states \u001b[39m=\u001b[39m resnet(hidden_states, temb)\n\u001b[0;32m--> 308\u001b[0m         hidden_states \u001b[39m=\u001b[39m attn(hidden_states, encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states, use_normal_attn\u001b[39m=\u001b[39;49muse_normal_attn)\u001b[39m.\u001b[39msample\n\u001b[1;32m    310\u001b[0m     output_states \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (hidden_states,)\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsamplers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/disks/disk_main/projects/Tune-A-Video/notebooks/../tuneavideo/models/attention.py:111\u001b[0m, in \u001b[0;36mTransformer3DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, return_dict, use_normal_attn)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m# Blocks\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks:\n\u001b[0;32m--> 111\u001b[0m     hidden_states \u001b[39m=\u001b[39m block(\n\u001b[1;32m    112\u001b[0m         hidden_states,\n\u001b[1;32m    113\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    114\u001b[0m         timestep\u001b[39m=\u001b[39;49mtimestep,\n\u001b[1;32m    115\u001b[0m         video_length\u001b[39m=\u001b[39;49mvideo_length,\n\u001b[1;32m    116\u001b[0m         use_normal_attn\u001b[39m=\u001b[39;49muse_normal_attn\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39m# Output\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_linear_projection:\n",
      "File \u001b[0;32m/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/disks/disk_main/projects/Tune-A-Video/notebooks/../tuneavideo/models/attention.py:252\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, attention_mask, video_length, use_normal_attn)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[39m# Cross-Attention\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     norm_hidden_states \u001b[39m=\u001b[39m (\n\u001b[1;32m    249\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(hidden_states, timestep) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ada_layer_norm \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(hidden_states)\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    251\u001b[0m     hidden_states \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn2(\n\u001b[1;32m    253\u001b[0m             norm_hidden_states, encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states, attention_mask\u001b[39m=\u001b[39;49mattention_mask, user_normal_attn\u001b[39m=\u001b[39;49muse_normal_attn\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    255\u001b[0m         \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39m# Feed-forward\u001b[39;00m\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(hidden_states)) \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/mnt/disks/disk_main/anaconda3/envs/tune_a_video/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: CrossAttention.forward() got an unexpected keyword argument 'use_normal_attn'"
     ]
    }
   ],
   "source": [
    "sample = torch.randn(1, 4, 3, 64, 64)\n",
    "timestep = 1\n",
    "encoder_hidden_states = torch.randn(1, 320, 768)\n",
    "hint = torch.randn(1, 3, 3, 512, 512)\n",
    "res = unet(sample, timestep, encoder_hidden_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune_a_video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc930b5ae691b227405cc9bff3dfc08ecacb7ab7388a794f9c4b730582c782dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
